#This is my rf model correcting zip code from numeric to factor, and eliminating a variety of variables for simplicity. It still 
#may be a better idea to run this on a % of the full observations since at present it won't complete the rf in R.

setwd("C:/Users/erinj/Desktop")


#clear current objects
rm(list = ls())

#read csv of cleaned data
training_data <- read.csv("311_cleaned.csv")

#open libraries
library(randomForest)
library(class)

#dropping factors (type) with over 53 categories
training_data$type <-NULL
training_data$open_dt <-NULL
training_data$target_dt <-NULL
training_data$closed_dt <-NULL
training_data$latitude <-NULL
training_data$longitude <-NULL
training_data$completion_hours <- as.numeric(training_data$completion_hours)
training_data$completion_time <-NULL
training_data$promised_time <-NULL
training_data$promised_hours <-NULL
training_data$location_zipcode <- as.factor(training_data$location_zipcode)
training_data$score <-NULL
training_data$city_council_district <- as.factor(training_data$city_council_district)

#random forest prediction
set.seed(71) 
rf <-randomForest(completion_hours~.,data=training_data, mtry=7, ntree=100) 
print(rf)

#drop if source type 

#tuning to pick best level of mtry....note that variable 12 is my completion time output variable after dropping as above
mtry <- tuneRF(training_data[-12,],training_data$completion_hours, ntreeTry=100,
               stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
print(best.m)

#Evaluate variable importance
importance(rf)
varImpPlot(rf)

